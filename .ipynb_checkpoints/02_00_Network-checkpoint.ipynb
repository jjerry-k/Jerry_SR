{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, activations, optimizers\n",
    "from utils import *\n",
    "\n",
    "def generator(model = 'vgg'):\n",
    "    block_dict = {\n",
    "        \"vgg\" : ['block5_conv3', 'block4_conv3', 'block3_conv3', 'block2_conv2', 'block1_conv2'],\n",
    "        \"resnet\" : ['activation_40', 'activation_22', 'activation_10', 'activation_1'],\n",
    "        \"xception\" : ['block13_sepconv2_bn', 'block4_sepconv2_bn', 'block3_sepconv2_bn', 'block1_conv1_act'],\n",
    "        \"mobile\" : ['conv_pw_11_relu', 'conv_pw_5_relu', 'conv_pw_3_relu', 'conv_pw_1_relu'], \n",
    "        \"dense\" : ['pool4_conv', 'pool3_conv', 'pool2_conv', 'conv1/relu']\n",
    "    }\n",
    "    # ========= Encoder ==========\n",
    "    print(\"=========== Information about Backbone ===========\")\n",
    "    base_model = load_base_model(model, input_shape=(None, None, 1))\n",
    "    x = layers.Conv2D(1024, 3, padding='same', activation='relu')(base_model.output) # H/32\n",
    "\n",
    "    # ========= Decoder ==========\n",
    "    x = layers.UpSampling2D(interpolation='bilinear')(x) # H/16\n",
    "    x = layers.concatenate([x, base_model.get_layer(block_dict[model][0]).output], axis = -1)\n",
    "    x = layers.SeparableConv2D(512, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.UpSampling2D(interpolation='bilinear')(x) # H/8\n",
    "    x = layers.concatenate([x, base_model.get_layer(block_dict[model][1]).output], axis = -1)\n",
    "    x = layers.SeparableConv2D(256, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.UpSampling2D(interpolation='bilinear')(x) # H/4\n",
    "    x = layers.concatenate([x, base_model.get_layer(block_dict[model][2]).output], axis = -1)\n",
    "    x = layers.SeparableConv2D(128, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.UpSampling2D(interpolation='bilinear')(x) # H/2\n",
    "    x = layers.concatenate([x, base_model.get_layer(block_dict[model][3]).output], axis = -1)\n",
    "    x = layers.SeparableConv2D(64, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    x = layers.UpSampling2D(interpolation='bilinear')(x) # H\n",
    "    if model == 'vgg':\n",
    "        x = layers.concatenate([x, base_model.get_layer(block_dict[model][4]).output], axis = -1)\n",
    "    x = layers.Conv2D(6, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    output1 = layers.DepthwiseConv2D(3, padding='same')(x)\n",
    "    output2 = layers.Lambda(layer_mean)(x)\n",
    "    Net = models.Model(base_model.input, [output1, output2])\n",
    "    \n",
    "    non_train_params = [layer.shape.num_elements() for layer in Net.non_trainable_weights]\n",
    "    non_train_params = sum(non_train_params)\n",
    "    print(\"\\n=========== Information about Whole Network ===========\")\n",
    "    print(\"Total Parameter of Model : \", format(Net.count_params(), ','))\n",
    "    print(\"Trainable Parameter of Model : \", format(Net.count_params()-non_train_params, ','))\n",
    "    print(\"Non-Trainable Parameter of Model : \", format(non_train_params, ','))\n",
    "    return Net\n",
    "\n",
    "def discriminator(model = 'vgg'):\n",
    "    block_dict = {\n",
    "        \"vgg\" : ['block5_conv3', 'block4_conv3', 'block3_conv3', 'block2_conv2', 'block1_conv2'],\n",
    "        \"resnet\" : ['activation_40', 'activation_22', 'activation_10', 'activation_1'],\n",
    "        \"xception\" : ['block13_sepconv2_bn', 'block4_sepconv2_bn', 'block3_sepconv2_bn', 'block1_conv1_act'],\n",
    "        \"mobile\" : ['conv_pw_11_relu', 'conv_pw_5_relu', 'conv_pw_3_relu', 'conv_pw_1_relu'], \n",
    "        \"dense\" : ['pool4_conv', 'pool3_conv', 'pool2_conv', 'conv1/relu']\n",
    "    }\n",
    "    # ========= Extractor ==========\n",
    "    print(\"=========== Information about Backbone ===========\")\n",
    "    base_model = load_base_model(model, input_shape=(None, None, 6))\n",
    "    texture = layers.Conv2D(1024, 3, padding='same', activation='relu')(base_model.output) # H/32\n",
    "    \n",
    "    # ========= Classifier ==========\n",
    "    x = layers.GlobalAvgPool2D()(texture)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    Net = models.Model(base_model.input, [output, texture])\n",
    "    \n",
    "    non_train_params = [layer.shape.num_elements() for layer in Net.non_trainable_weights]\n",
    "    non_train_params = sum(non_train_params)\n",
    "    print(\"\\n=========== Information about Whole Network ===========\")\n",
    "    print(\"Total Parameter of Model : \", format(Net.count_params(), ','))\n",
    "    print(\"Trainable Parameter of Model : \", format(Net.count_params()-non_train_params, ','))\n",
    "    print(\"Non-Trainable Parameter of Model : \", format(non_train_params, ','))\n",
    "    return Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet = generator(model='mobile')\n",
    "dnet = discriminator(model='mobile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net.compile(optimizer=optimizers.Adam(epsilon=1e-8), loss = ['mse'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
